{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-15T08:55:49.375029Z",
     "start_time": "2019-09-15T08:55:44.752793Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3f6cd67c398a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mq_learning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_absolute_percentage_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mq_learning_rmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mq_learning_mse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-3f6cd67c398a>\u001b[0m in \u001b[0;36mmean_absolute_percentage_error\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmean_absolute_percentage_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "from sewar.full_ref import msssim, uqi, ssim, rmse, mse\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "import numpy as np\n",
    "import cv2 \n",
    "img1 = cv2.imread('rect_512spp_explicitsampling_new.jpg',0)\n",
    "img2 = cv2.imread('rect_32spp_importancesampl.jpg',0)\n",
    "img3 = cv2.imread('rect_32spp_randomsampl.jpg',0)\n",
    "img4 = cv2.imread('rect_32spp_explicitlight_new.jpg',0)\n",
    "img5 = cv2.imread('qlearning_16spp_proportional.jpg',0)\n",
    "img6 = cv2.imread('qlearning-16spp-proportional-lr1-newupdate.jpg',0)\n",
    "img7 = cv2.imread('qlearning-16spp-proportional-lr1-newupdate-state5.jpg',0)\n",
    "img8 = cv2.imread('qlearning-16spp-proportional-lr1-oldupdate-state5.jpg',0)\n",
    "img9 = cv2.imread('qlearning-32spp-proportional-lr1-oldupdate-state5.jpg',0)\n",
    "img10 = cv2.imread('qlearning-32spp-proportional-lr1-oldupdate-state10.jpg',0)\n",
    "img11 = cv2.imread('qlearning-16spp-proportional-lr1-oldupdate-state5-action96.jpg',0)\n",
    "img12 = cv2.imread('qlearning-32spp-proportional-lr1-oldupdate-state5-action96.jpg',0)\n",
    "img13 = cv2.imread('qlearning-32spp-proportional-lr1-oldupdate-state5-action72.jpg',0)\n",
    "img14 = cv2.imread('qlearning-32spp-proportional-lr1-oldupdate-state5-action72-2.jpg',0)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / (y_true+0.001))) * 100\n",
    "\n",
    "\n",
    "\n",
    "q_learning = mean_absolute_percentage_error(img1, img13)\n",
    "q_learning_rmse = rmse(img1, img13)\n",
    "q_learning_mse = mse(img1, img13)\n",
    "\n",
    "print('Q-learning mape: ', q_learning)\n",
    "print('Q-learning rmse: ', q_learning_rmse)\n",
    "print('Q-learning mse: ', q_learning_mse)\n",
    "\n",
    "imp_sampl_rmse = rmse(img4, img2)\n",
    "imp_sampl_mse = mse(img1, img2)\n",
    "imp_sampl = mean_absolute_percentage_error(img1, img2)\n",
    "print('Imp samp mape: ', imp_sampl)\n",
    "print('Imp samp rmse: ', imp_sampl_rmse)\n",
    "print('Imp samp mse: ', imp_sampl_rmse)\n",
    "\n",
    "'''\n",
    "print('IMPORTANCE SAMPLING')\n",
    "print(msssim(img1,img2))\n",
    "print((1+ssim(img1,img2))/2)\n",
    "print('RANDOM SAMPLING')\n",
    "print(msssim(img1,img3))\n",
    "print((1+ssim(img1,img3))/2)\n",
    "print('EXPLICIT LIGHT')\n",
    "print(msssim(img1,img4))\n",
    "print((1+ssim(img1,img4))/2)\n",
    "\n",
    "print('Q-VALUE-OLD-UPDATE-STATE5-32spp')\n",
    "print(msssim(img1,img9))\n",
    "print((1+ssim(img1,img9))/2)\n",
    "\n",
    "print('Q-VALUE-OLD-UPDATE-STATE10-32spp')\n",
    "print(msssim(img1,img10))\n",
    "print((1+ssim(img1,img10))/2)\n",
    "\n",
    "print('Q-VALUE-OLD-UPDATE-STATE5-16spp-action96')\n",
    "print(msssim(img1,img11))\n",
    "print((1+ssim(img1,img11))/2)\n",
    "\n",
    "print('Q-VALUE-OLD-UPDATE-STATE5-32spp-action96')\n",
    "print(msssim(img1,img12))\n",
    "print((1+ssim(img1,img12))/2)\n",
    "\n",
    "print('Q-VALUE-OLD-UPDATE-STATE5-32spp-action72')\n",
    "print(msssim(img1,img13))\n",
    "print((1+ssim(img1,img13))/2)\n",
    "\n",
    "print('Q-VALUE-OLD-UPDATE-STATE5-32spp-action72-2')\n",
    "print(msssim(img1,img14))\n",
    "print((1+ssim(img1,img14))/2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T20:28:16.242424Z",
     "start_time": "2019-07-02T20:28:16.201502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-LEARNING\n",
      "1229.4397735595703\n",
      "EXPLICIT LIGHT SAMPLING\n",
      "1145.8162117004395\n"
     ]
    }
   ],
   "source": [
    "from sewar.full_ref import msssim, uqi, ssim, mse\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "import numpy as np\n",
    "import cv2 \n",
    "img1 = cv2.imread('newscene2-512spp-importancesampling.jpg',0)\n",
    "img2 = cv2.imread('newscene2-16spp-qlearning-2.jpg',0)\n",
    "img3 = cv2.imread('newscene2-16spp-explicitlight.jpg',0)\n",
    "\n",
    "print('Q-LEARNING')\n",
    "print(mse(img1,img2))\n",
    "\n",
    "print('EXPLICIT LIGHT SAMPLING')\n",
    "print(mse(img1,img3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:41:48.261563Z",
     "start_time": "2019-08-26T06:41:48.220703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.12023444745108\n",
      "93.0204224307662\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "img1 = Image.open('rect_512spp_explicitsampling_new.jpg').convert(\"L\")\n",
    "img2 = Image.open('rect_32spp_importancesampl.jpg').convert(\"L\")\n",
    "img4 = Image.open('rect_32spp_explicitlight_new.jpg').convert(\"L\")\n",
    "img13 = Image.open('qlearning-32spp-proportional-lr1-oldupdate-state5-action72.jpg').convert(\"L\")\n",
    "\n",
    "im1arr = np.array(img1) # im2arr.shape: height x width x channel\n",
    "im13arr= np.array(img13)\n",
    "im2arr= np.array(img2)\n",
    "im4arr= np.array(img4)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / (y_true+0.001))) * 100\n",
    "\n",
    "q_learning = mean_absolute_percentage_error(im1arr, im13arr)\n",
    "imp_samp = mean_absolute_percentage_error(im1arr, im2arr)\n",
    "print(q_learning)\n",
    "print(imp_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T12:45:04.836888Z",
     "start_time": "2019-08-27T12:45:04.815944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.05259869627633\n",
      "71.85564718750057\n",
      "75.24924944219565\n",
      "74.45871291499272\n",
      "69.82770755767254\n",
      "69.34583657605731\n",
      "71.37551353178048\n",
      "73.20413800363099\n",
      "71.18183013413318\n",
      "71.81830512871016\n",
      "75.84786887303979\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "img01 = Image.open('scenedqn-256spp-explicit-128.png').convert(\"RGB\")\n",
    "img02 = Image.open('py-smallpt-30000L2000-72actions-lineareps-0001lr-500nnx3-targetnet.png').convert(\"RGB\")\n",
    "img03 = Image.open('py-smallpt-10000L3000-72actions-lineareps-0001lr-500nnx3-2.png').convert(\"RGB\")\n",
    "img04 = Image.open('py-smallpt-25000L2000-72actions-lineareps-0005lr-1000nnx3-targetnet-SGD.png').convert(\"RGB\")\n",
    "img05 = Image.open('py-smallpt-10000L3500-72actions-lineareps-0001lr-500nnx3-maxQ.png').convert(\"RGB\")\n",
    "img06 = Image.open('py-smallpt-10000L5000-72actions-lineareps-00001lr-800nnx4-KERNEL16.png').convert(\"RGB\")\n",
    "img07 = Image.open('py-smallpt-10000L5000-72actions-lineareps-00001lr-500nnx4-KERNEL16.png').convert(\"RGB\")\n",
    "img08 = Image.open('scenedqn-8spp-qlearning.png').convert(\"RGB\")\n",
    "img09 = Image.open('py-smallpt-10000L3500-72actions-lineareps-0001lr-500nnx4-targetnet.png').convert(\"RGB\")\n",
    "img010 = Image.open('py-smallpt-10000L3500-72actions-lineareps-0001lr-500nnx4-KERNEL16-targetnet.png').convert(\"RGB\")\n",
    "img011 = Image.open('py-smallpt-10000L3500-72actions-lineareps-000lr-500nnx4-KERNEL16.png').convert(\"RGB\")\n",
    "img012 = Image.open('py-smallpt-10000L3500-72actions-lineareps-lr1-500nnx4-KERNEL16-SGD.png').convert(\"RGB\")\n",
    "img012 = Image.open('py-smallpt-10000L3500-72actions-lineareps-lr1-500nnx4-KERNEL16-SGD.png').convert(\"RGB\")\n",
    "\n",
    "\n",
    "img01arr= np.array(img01) \n",
    "img02arr= np.array(img02)\n",
    "img03arr= np.array(img03)\n",
    "img04arr= np.array(img04)\n",
    "img05arr= np.array(img05)\n",
    "img06arr= np.array(img06)\n",
    "img07arr= np.array(img07)\n",
    "img08arr= np.array(img08)\n",
    "img09arr= np.array(img09)\n",
    "img010arr= np.array(img010)\n",
    "img011arr= np.array(img011)\n",
    "img012arr= np.array(img012)\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / (y_true+0.001))) * 100\n",
    "\n",
    "mape1 = mean_absolute_percentage_error(img01arr, img02arr)\n",
    "mape2 = mean_absolute_percentage_error(img01arr, img03arr)\n",
    "mape3 = mean_absolute_percentage_error(img01arr, img04arr)\n",
    "mape4 = mean_absolute_percentage_error(img01arr, img05arr)\n",
    "mape5 = mean_absolute_percentage_error(img01arr, img06arr)\n",
    "mape6 = mean_absolute_percentage_error(img01arr, img07arr)\n",
    "mape7 = mean_absolute_percentage_error(img01arr, img08arr)\n",
    "mape8 = mean_absolute_percentage_error(img01arr, img09arr)\n",
    "mape9 = mean_absolute_percentage_error(img01arr, img010arr)\n",
    "mape10 = mean_absolute_percentage_error(img01arr, img011arr)\n",
    "mape11 = mean_absolute_percentage_error(img01arr, img012arr)\n",
    "\n",
    "print(mape1)\n",
    "print(mape2)\n",
    "print(mape3)\n",
    "print(mape4)\n",
    "print(mape5)\n",
    "print(mape6)\n",
    "print(mape7)\n",
    "print(mape8)\n",
    "print(mape9)\n",
    "print(mape10)\n",
    "print(mape11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size 128, scene 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sewar.full_ref import msssim, uqi, ssim, mse\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "img00 = Image.open('scenedqn-256spp-explicit-128.png').convert(\"RGB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size 256, scene 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T15:10:43.047855Z",
     "start_time": "2019-09-27T15:10:42.039503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM ------------------------------------------\n",
      "DQN One-Blob 1:  0.15701053435316642\n",
      "DQN One-Blob 2:  0.14361849596747986\n",
      "DQN One-Blob 3:  0.15639140492251544\n",
      "DQN One-Blob 4:  0.1581080371868891\n",
      "AVERAGE Q-Learning:  0.13495377576478879         XXXXX\n",
      "SD Q-Learning:  0.0005090061216682166         XXXXX\n",
      "AVERAGE Importance Sampling:  0.11073388906379181         XXXXX\n",
      "SD Importance Sampling:  0.0006280466161856966         XXXXX\n",
      "DQN NO One-Blob:  0.14361849596747986\n",
      "Q-learning 2:  0.13112409986044835\n",
      "Q-learning 2:  0.13112409986044835\n",
      "MSE --------------------------------------------\n",
      "mse1, DQN One-Blob 1:  0.023531769397212018\n",
      "mse1, DQN One-Blob 2:  0.023476519557156506\n",
      "mse1, DQN One-Blob 3:  0.02335095030244277\n",
      "AVERAGE Q-Learning:  0.027601528568113827         XXXXX\n",
      "SD Q-Learning:  0.00020999746899561016         XXXXX\n",
      "AVERAGE Importance Sampling:  0.04095550969666614         XXXXX\n",
      "SD Importance Sampling:  0.0003560745773510871         XXXXX\n",
      "mse2, Q-Learning:  0.02973862623199811\n",
      "mse3, Importance Sampling:  0.04157594517746079\n",
      "mse4, DQN NO One-Blob:  0.02852645965932074\n",
      "Q-Learning 2:  0.029129013302050286\n",
      "Q-Learning 2:  0.029129013302050286\n"
     ]
    }
   ],
   "source": [
    "from skimage.measure import compare_ssim, compare_mse\n",
    "from skimage import img_as_float\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Reference image\n",
    "img00 = Image.open('scenedqn-5120spp-explicit-256.png').convert(\"RGB\")\n",
    "\n",
    "# DQN\n",
    "img01 = Image.open('py-smallpt-10000L3500-72actions-lineareps-lr00001-1000nnx4-KERNEL16-targetnet-32spp-256.png').convert(\"RGB\")\n",
    "img05 = Image.open('py-smallpt-10000L3500-72actions-lineareps-lr00001-1000nnx4-KERNEL16-targetnet-32spp-256-compare1.png').convert(\"RGB\")\n",
    "img06 = Image.open('py-smallpt-10000L3500-72actions-lineareps-lr00001-1000nnx4-KERNEL16-targetnet-32spp-256-compare2.png').convert(\"RGB\")\n",
    "\n",
    "# Q-Learning\n",
    "img02 = Image.open('scenedqn-32spp-qlearning-256-tr128.png').convert(\"RGB\")\n",
    "img11 = Image.open('scenedqn-qlearning-32spp-avg0.png').convert(\"RGB\")\n",
    "img12 = Image.open('scenedqn-qlearning-32spp-avg1.png').convert(\"RGB\")\n",
    "img13 = Image.open('scenedqn-qlearning-32spp-avg2.png').convert(\"RGB\")\n",
    "img14 = Image.open('scenedqn-qlearning-32spp-avg3.png').convert(\"RGB\")\n",
    "img15 = Image.open('scenedqn-qlearning-32spp-avg4.png').convert(\"RGB\")\n",
    "img16 = Image.open('scenedqn-qlearning-32spp-2.png').convert(\"RGB\")\n",
    "img17 = Image.open('scenedqn-qlearning-32spp-2-depth6.png').convert(\"RGB\")\n",
    "\n",
    "\n",
    "# Cosine importance sampling\n",
    "img03 = Image.open('scenedqn-32spp-importancesampling-256.png').convert(\"RGB\")\n",
    "img07 = Image.open('scenedqn-importancesampling-32spp-avg0.png').convert(\"RGB\")\n",
    "img08 = Image.open('scenedqn-importancesampling-32spp-avg1.png').convert(\"RGB\")\n",
    "img09 = Image.open('scenedqn-importancesampling-32spp-avg2.png').convert(\"RGB\")\n",
    "img10 = Image.open('scenedqn-importancesampling-32spp-avg3.png').convert(\"RGB\")\n",
    "\n",
    "# Miscellaneous\n",
    "img04 = Image.open('py-smallpt-10000L3500-72actions-lineareps-0001lr-1000nnx4-targetnet-compare-32spp-256.png').convert(\"RGB\")\n",
    "img05 = Image.open('py-smallpt-10000L3500-72actions-lineareps-lr00001-1000nnx4-KERNEL16-targetnet-32spp-256-compare1.png').convert(\"RGB\")\n",
    "img06 = Image.open('py-smallpt-10000L3500-72actions-lineareps-lr00001-1000nnx4-KERNEL16-targetnet-32spp-256-compare2.png').convert(\"RGB\")\n",
    "\n",
    "# Load images as arrays\n",
    "img00arr= np.array(img00) \n",
    "img01arr= np.array(img01)\n",
    "img02arr= np.array(img02)\n",
    "img03arr= np.array(img03)\n",
    "img04arr= np.array(img04)\n",
    "img05arr= np.array(img05)\n",
    "img06arr= np.array(img06)\n",
    "img07arr= np.array(img07)\n",
    "img08arr= np.array(img08)\n",
    "img09arr= np.array(img09)\n",
    "img10arr= np.array(img10)\n",
    "img11arr= np.array(img11)\n",
    "img12arr= np.array(img12)\n",
    "img13arr= np.array(img13)\n",
    "img14arr= np.array(img14)\n",
    "img15arr= np.array(img15)\n",
    "img16arr= np.array(img16)\n",
    "img17arr= np.array(img17)\n",
    "\n",
    "# Compare SSIM\n",
    "ssim1 = compare_ssim(img00arr, img01arr,multichannel=True)\n",
    "ssim2 = compare_ssim(img00arr, img02arr,multichannel=True)\n",
    "ssim3 = compare_ssim(img00arr, img03arr,multichannel=True)\n",
    "ssim4 = compare_ssim(img00arr, img04arr,multichannel=True)\n",
    "ssim5 = compare_ssim(img00arr, img05arr,multichannel=True)\n",
    "ssim6 = compare_ssim(img00arr, img06arr,multichannel=True)\n",
    "ssim7 = compare_ssim(img00arr, img07arr,multichannel=True)\n",
    "ssim8 = compare_ssim(img00arr, img08arr,multichannel=True)\n",
    "ssim9 = compare_ssim(img00arr, img09arr,multichannel=True)\n",
    "ssim10 = compare_ssim(img00arr, img10arr,multichannel=True)\n",
    "ssim11 = compare_ssim(img00arr, img11arr,multichannel=True)\n",
    "ssim12 = compare_ssim(img00arr, img12arr,multichannel=True)\n",
    "ssim13 = compare_ssim(img00arr, img13arr,multichannel=True)\n",
    "ssim14 = compare_ssim(img00arr, img14arr,multichannel=True)\n",
    "ssim15 = compare_ssim(img00arr, img15arr,multichannel=True)\n",
    "ssim16 = compare_ssim(img00arr, img16arr,multichannel=True)\n",
    "ssim17 = compare_ssim(img00arr, img16arr,multichannel=True)\n",
    "\n",
    "# Compare MSE\n",
    "mse1 = compare_mse(img_as_float(img00arr), img_as_float(img01arr))\n",
    "mse2 = compare_mse(img_as_float(img00arr), img_as_float(img02arr))\n",
    "mse3 = compare_mse(img_as_float(img00arr), img_as_float(img03arr))\n",
    "mse4 = compare_mse(img_as_float(img00arr), img_as_float(img04arr))\n",
    "mse5 = compare_mse(img_as_float(img00arr), img_as_float(img05arr))\n",
    "mse6 = compare_mse(img_as_float(img00arr), img_as_float(img06arr))\n",
    "mse7 = compare_mse(img_as_float(img00arr), img_as_float(img07arr))\n",
    "mse8 = compare_mse(img_as_float(img00arr), img_as_float(img08arr))\n",
    "mse9 = compare_mse(img_as_float(img00arr), img_as_float(img09arr))\n",
    "mse10 = compare_mse(img_as_float(img00arr), img_as_float(img10arr))\n",
    "mse11= compare_mse(img_as_float(img00arr), img_as_float(img11arr))\n",
    "mse12= compare_mse(img_as_float(img00arr), img_as_float(img12arr))\n",
    "mse13= compare_mse(img_as_float(img00arr), img_as_float(img13arr))\n",
    "mse14= compare_mse(img_as_float(img00arr), img_as_float(img14arr))\n",
    "mse15 = compare_mse(img_as_float(img00arr), img_as_float(img15arr))\n",
    "mse16 = compare_mse(img_as_float(img00arr), img_as_float(img16arr))\n",
    "mse17 = compare_mse(img_as_float(img00arr), img_as_float(img17arr))\n",
    "\n",
    "\n",
    "print(\"SSIM ------------------------------------------\")\n",
    "print(\"DQN One-Blob 1: \", ssim1)\n",
    "print(\"DQN One-Blob 2: \", ssim4)\n",
    "print(\"DQN One-Blob 3: \", ssim5)\n",
    "print(\"DQN One-Blob 4: \", ssim6)\n",
    "\n",
    "\n",
    "print(\"AVERAGE Q-Learning: \", (ssim11 + ssim12 + ssim13+ ssim14+ ssim15)/5, \"        XXXXX\" )\n",
    "print(\"SD Q-Learning: \", np.std(np.array([ssim11, ssim12, ssim13, ssim14, ssim15])), \"        XXXXX\")\n",
    "\n",
    "print(\"AVERAGE Importance Sampling: \", (ssim10 + ssim9 + ssim8+ ssim7+ ssim3)/5, \"        XXXXX\" )\n",
    "print(\"SD Importance Sampling: \", np.std(np.array([ssim10,ssim9,ssim8,ssim7, ssim3])), \"        XXXXX\")\n",
    "\n",
    "print(\"DQN NO One-Blob: \", ssim4)\n",
    "\n",
    "print(\"Q-learning 2: \", ssim16)\n",
    "print(\"Q-learning 2: \", ssim17)\n",
    "\n",
    "\n",
    "print(\"MSE --------------------------------------------\")\n",
    "print(\"mse1, DQN One-Blob 1: \", mse1)\n",
    "print(\"mse1, DQN One-Blob 2: \", mse5)\n",
    "print(\"mse1, DQN One-Blob 3: \", mse6)\n",
    "\n",
    "print(\"AVERAGE Q-Learning: \", (mse11 + mse12 + mse13+ mse14+ mse15)/5, \"        XXXXX\" )\n",
    "print(\"SD Q-Learning: \", np.std(np.array([mse11, mse12, mse13, mse14, mse15])), \"        XXXXX\")\n",
    "\n",
    "print(\"AVERAGE Importance Sampling: \", (mse10 +mse9 + mse8+ mse7+ mse3)/5, \"        XXXXX\" )\n",
    "print(\"SD Importance Sampling: \", np.std(np.array([mse10,mse9,mse8,mse7, mse3])), \"        XXXXX\")\n",
    "\n",
    "\n",
    "print(\"mse2, Q-Learning: \", mse2)\n",
    "print(\"mse3, Importance Sampling: \", mse3)\n",
    "print(\"mse4, DQN NO One-Blob: \", mse4)\n",
    "\n",
    "print(\"Q-Learning 2: \", mse16)\n",
    "print(\"Q-Learning 2: \", mse17)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size 128, scene 2 -- NOOO!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T08:55:13.400203Z",
     "start_time": "2019-09-02T08:55:13.328427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM\n",
      "ssim1:  0.06653407713864565\n",
      "ssim2:  0.0716797647959856\n",
      "ssim2:  0.06717034764792111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\skimage\\util\\arraycrop.py:177: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  cropped = ar[slices]\n"
     ]
    }
   ],
   "source": [
    "from skimage.measure import compare_ssim, compare_mse\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load images\n",
    "img00 = Image.open('scenedqn2-256spp-explicit-128.png')\n",
    "img01 = Image.open('py-smallpt-2-10000L2000-72actions-lineareps-lr00001-500nnx4-KERNEL16-targetnet.png').convert(\"RGB\")\n",
    "img02 = Image.open('py-smallpt-2-10000L2000-72actions-lineareps-lr00001-1000nnx4-KERNEL16-targetnet-8spp.png').convert(\"RGB\")\n",
    "img03 = Image.open('scenedqn2-8spp-qlearning-128.png').convert(\"RGB\")\n",
    "\n",
    "\n",
    "# Load images as arrays\n",
    "img00arr= np.array(img00) \n",
    "img01arr= np.array(img01)\n",
    "img02arr= np.array(img02)\n",
    "img03arr= np.array(img03)\n",
    "\n",
    "# Compare SSIM\n",
    "ssim1 = compare_ssim(img00arr, img01arr, multichannel=True)\n",
    "ssim2 = compare_ssim(img00arr, img02arr,multichannel=True)\n",
    "ssim3 = compare_ssim(img00arr, img03arr,multichannel=True)\n",
    "\n",
    "# Compare MSE\n",
    "mse1= compare_mse(img_as_float(img00arr), img_as_float(img01arr))\n",
    "mse2= compare_mse(img_as_float(img00arr), img_as_float(img02arr))\n",
    "mse3 = compare_mse(img_as_float(img00arr), img_as_float(img03arr))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"SSIM --------------------------------------------\")\n",
    "print(\"ssim1: \", ssim1)\n",
    "print(\"ssim2: \", ssim2)\n",
    "print(\"ssim2: \", ssim3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size 256, scene 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T20:39:01.572755Z",
     "start_time": "2019-09-26T20:39:01.280878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM -----------------------------\n",
      "DQN:  0.09702848709585893\n",
      "Q Learning:  0.0716849632503847\n",
      "Importance sampling:  0.05747409987141163\n",
      "Q Learning 2, 3 passes:  0.07336074228523426\n",
      "Q Learning 2, depth 6:  0.07718469395868077\n",
      "Q Learning 2, noise red depth 6:  0.07562471027220176\n",
      "DQN, noise reduction:  0.0891748118890266\n",
      "MSE -----------------------------\n",
      "DQN:  0.02384019858773268\n",
      "Q Learning:  0.028021206052184455\n",
      "Importance sampling:  0.035961289083775876\n",
      "Q Learning 2, 3 passes:  0.02690946902370782\n",
      "Q Learning 2, depth 6:  0.02588271885487753\n",
      "Q Learning 2, noise red depth:  0.026054595904244554\n",
      "DQN, noise reduction:  0.026529425797394632\n"
     ]
    }
   ],
   "source": [
    "from skimage.measure import compare_ssim, compare_mse\n",
    "from skimage import img_as_float\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load images\n",
    "img00 = Image.open('scenedqn2-5120spp-explicit-256.png').convert(\"RGB\")\n",
    "img01 = Image.open('py-smallpt-2-10000L2000-72actions-lineareps-lr00001-1000nnx4-KERNEL16-targetnet-32spp-256.png').convert(\"RGB\")\n",
    "img02 = Image.open('scenedqn2-32spp-qlearning-256-tr128.png').convert(\"RGB\")\n",
    "img03 = Image.open('scenedqn2-32spp-importancesampling-256.png').convert(\"RGB\")\n",
    "img04 = Image.open('scenedqn2-qlearning-256-128tr-2.png').convert(\"RGB\")\n",
    "img05 = Image.open('scenedqn2-qlearning-32spp-2-depth6.png').convert(\"RGB\")\n",
    "img06 = Image.open('scenedqn2-qlearning-depth6-noisereduction-31.png').convert(\"RGB\")\n",
    "img07 = Image.open('noise_reduction/py-smallpt2-10000L2000-72actions-lineareps-lr00001-1000nnx4-KERNEL16-targetnet-32spp-256-depth6-noisereduction-AGAIN-31.png').convert(\"RGB\")\n",
    "\n",
    "\n",
    "# Load images as arrays\n",
    "img00arr= np.array(img00) \n",
    "img01arr= np.array(img01)\n",
    "img02arr= np.array(img02)\n",
    "img03arr= np.array(img03)\n",
    "img04arr= np.array(img04)\n",
    "img05arr= np.array(img05)\n",
    "img06arr= np.array(img06)\n",
    "img07arr= np.array(img07)\n",
    "\n",
    "# Compare SSIM\n",
    "ssim1 = compare_ssim(img00arr, img01arr, multichannel=True)\n",
    "ssim2 = compare_ssim(img00arr, img02arr, multichannel=True)\n",
    "ssim3 = compare_ssim(img00arr, img03arr, multichannel=True)\n",
    "ssim4 = compare_ssim(img00arr, img04arr,multichannel=True)\n",
    "ssim5 = compare_ssim(img00arr, img05arr,multichannel=True)\n",
    "ssim6 = compare_ssim(img00arr, img06arr,multichannel=True)\n",
    "ssim7 = compare_ssim(img00arr, img07arr,multichannel=True)\n",
    "\n",
    "# Compare MSE\n",
    "mse1= compare_mse(img_as_float(img00arr), img_as_float(img01arr))\n",
    "mse2= compare_mse(img_as_float(img00arr), img_as_float(img02arr))\n",
    "mse3 = compare_mse(img_as_float(img00arr), img_as_float(img03arr))\n",
    "mse4 = compare_mse(img_as_float(img00arr), img_as_float(img04arr))\n",
    "mse5 = compare_mse(img_as_float(img00arr), img_as_float(img05arr))\n",
    "mse6 = compare_mse(img_as_float(img00arr), img_as_float(img06arr))\n",
    "mse7 = compare_mse(img_as_float(img00arr), img_as_float(img07arr))\n",
    "\n",
    "\n",
    "print(\"SSIM -----------------------------\")\n",
    "print(\"DQN: \", ssim1)\n",
    "print(\"Q Learning: \", ssim2)\n",
    "print(\"Importance sampling: \", ssim3)\n",
    "print(\"Q Learning 2, 3 passes: \", ssim4)\n",
    "print(\"Q Learning 2, depth 6: \", ssim5)\n",
    "print(\"Q Learning 2, noise red depth 6: \", ssim6)\n",
    "print(\"DQN, noise reduction: \", ssim7)\n",
    "\n",
    "\n",
    "print(\"MSE -----------------------------\")\n",
    "print(\"DQN: \", mse1)\n",
    "print(\"Q Learning: \", mse2)\n",
    "print(\"Importance sampling: \", mse3)\n",
    "print(\"Q Learning 2, 3 passes: \", mse4)\n",
    "print(\"Q Learning 2, depth 6: \", mse5)\n",
    "print(\"Q Learning 2, noise red depth: \", mse6)\n",
    "print(\"DQN, noise reduction: \", mse7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size 128, scene 3 -- NOOO!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-15T12:32:45.829361Z",
     "start_time": "2019-09-15T12:32:45.804836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM\n",
      "ssim1:  0.05711412957910069\n",
      "ssim2:  0.060337600111384254\n",
      "ssim3:  0.04998601140372761\n"
     ]
    }
   ],
   "source": [
    "from skimage.measure import compare_ssim, compare_mse\n",
    "from skimage import img_as_float\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "img00 = Image.open('scenedqn3-256spp-explicit-128.png')\n",
    "img01 = Image.open('py-smallpt-3-10000L2000-72actions-lineareps-lr00001-1000nnx4-KERNEL16-targetnet.png').convert(\"RGB\")\n",
    "img02 = Image.open('scenedqn3-8spp-qlearning-128.png').convert(\"RGB\")\n",
    "img03 = Image.open('py-smallpt-3-10000L2000-72actions-lineareps-lr00001-100nnx3-KERNEL16-targetnet.png').convert(\"RGB\")\n",
    "\n",
    "\n",
    "img00arr= np.array(img00) \n",
    "img01arr= np.array(img01)\n",
    "img02arr= np.array(img02)\n",
    "img03arr= np.array(img03)\n",
    "\n",
    "ssim1 = compare_ssim(img00arr, img01arr, multichannel=True)\n",
    "ssim2 = compare_ssim(img00arr, img02arr,multichannel=True)\n",
    "ssim3 = compare_ssim(img00arr, img03arr,multichannel=True)\n",
    "\n",
    "\n",
    "print(\"SSIM\")\n",
    "print(\"ssim1: \", ssim1)\n",
    "print(\"ssim2: \", ssim2)\n",
    "print(\"ssim3: \", ssim3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size 256, scene 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T20:53:40.273367Z",
     "start_time": "2019-09-26T20:53:39.920788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM ------------------------\n",
      "Q-Learning:  0.07875214704563782\n",
      "DQN-1000nn:  0.07041334587950977\n",
      "importance sampling:  0.07000078562568822\n",
      "DQN-1000nn noise reduction:  0.060427711867839094\n",
      "DQN-1000nn 2:  0.058229070904775006\n",
      "Q-Learning 2:  0.0859104609335755\n",
      "Q-Learning 2, noise reduction depth 6:  0.08329097676552451\n",
      "Q-Learning 2, depth 6:  0.08424261719795177\n",
      "DQN noise reduction:  0.06648020927737434\n",
      "DQN noise reduction:  0.06648020927737434\n",
      "MSE --------------\n",
      "Q-Learning:  0.036980895878763576\n",
      "DQN-1000nn:  0.04629953210604095\n",
      "importance sampling:  0.04479363929976351\n",
      "DQN-1000nn noise reduction:  0.05260351931698946\n",
      "DQN-1000nn 2:  0.05477773378678472\n",
      "Q-Learning 2:  0.03329260161606513\n",
      "Q-Learning 2, depth 6:  0.03450039404165464\n",
      "DQN noise reduction:  0.04888333948456322\n",
      "DQN noise reduction:  0.04888333948456322\n"
     ]
    }
   ],
   "source": [
    "from skimage.measure import compare_ssim, compare_mse\n",
    "from skimage import img_as_float\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load images\n",
    "img00 = Image.open('scenedqn3-5120spp-explicit-256.png').convert(\"RGB\")\n",
    "img01 = Image.open('py-smallpt-3-10000L2000-72actions-lineareps-lr00001-1000nnx4-KERNEL16-targetnet-32spp-256.png').convert(\"RGB\")\n",
    "img02 = Image.open('scenedqn3-32spp-qlearning-256-tr128.png').convert(\"RGB\")\n",
    "img03 = Image.open('py-smallpt-3-10000L2000-72actions-lineareps-lr00001-1500nnx4-KERNEL16-targetnet-32spp-256.png').convert(\"RGB\")\n",
    "img04 = Image.open('scenedqn3-32spp-importancesampling-256.png').convert(\"RGB\")\n",
    "img05 = Image.open('py-smallpt3-10000L2000-72actions-lineareps-lr00001-1000nnx4-KERNEL16-targetnet-32spp-256-noisereduction-31.png').convert(\"RGB\")\n",
    "img06 = Image.open('py-smallpt3-10000L2000-72actions-lineareps-lr00001-1000nnx4-KERNEL16-targetnet-2.png').convert(\"RGB\")\n",
    "img07 = Image.open('scenedqn3-qlearning-32spp-2.png').convert(\"RGB\")\n",
    "img08 = Image.open('scenedqn3-qlearning-depth6-noisereduction-31.png').convert(\"RGB\")\n",
    "img09 = Image.open('scenedqn3-qlearning-32spp-depth6.png').convert(\"RGB\")\n",
    "img10 = Image.open('noise_reduction/py-smallpt3-10000L2000-72actions-lineareps-lr00001-1000nnx4-KERNEL16-targetnet-32spp-256-depth6-noisereduction-AGAIN-31.png').convert(\"RGB\")\n",
    "img11 = Image.open('py-smallpt3-TO-CHECK-IF-ITS-512kb-DEPTH-AFTER.png').convert(\"RGB\")\n",
    "\n",
    "# Load images as arrays\n",
    "img00arr= np.array(img00) \n",
    "img01arr= np.array(img01)\n",
    "img02arr= np.array(img02)\n",
    "img03arr= np.array(img03)\n",
    "img04arr= np.array(img04)\n",
    "img05arr= np.array(img05)\n",
    "img06arr= np.array(img06)\n",
    "img07arr= np.array(img07)\n",
    "img08arr= np.array(img08)\n",
    "img09arr= np.array(img09)\n",
    "img10arr= np.array(img10)\n",
    "img11arr= np.array(img11)\n",
    "\n",
    "# Compare SSIM\n",
    "ssim1 = compare_ssim(img00arr, img01arr, multichannel=True)\n",
    "ssim2 = compare_ssim(img00arr, img02arr,multichannel=True)\n",
    "#ssim3 = compare_ssim(img00arr, img03arr,multichannel=True)\n",
    "ssim4 = compare_ssim(img00arr, img04arr,multichannel=True)\n",
    "ssim5 = compare_ssim(img00arr, img05arr,multichannel=True)\n",
    "ssim6 = compare_ssim(img00arr, img06arr,multichannel=True)\n",
    "ssim7 = compare_ssim(img00arr, img07arr,multichannel=True)\n",
    "ssim8 = compare_ssim(img00arr, img08arr,multichannel=True)\n",
    "ssim9 = compare_ssim(img00arr, img09arr,multichannel=True)\n",
    "ssim10 = compare_ssim(img00arr, img10arr,multichannel=True)\n",
    "ssim11 = compare_ssim(img00arr, img11arr,multichannel=True)\n",
    "\n",
    "# Compare mse\n",
    "mse1= compare_mse(img_as_float(img00arr), img_as_float(img01arr))\n",
    "mse2= compare_mse(img_as_float(img00arr), img_as_float(img02arr))\n",
    "#mse3 = compare_mse(img_as_float(img00arr), img_as_float(img03arr))\n",
    "mse4 = compare_mse(img_as_float(img00arr), img_as_float(img04arr))\n",
    "mse5 = compare_mse(img_as_float(img00arr), img_as_float(img05arr))\n",
    "mse6 = compare_mse(img_as_float(img00arr), img_as_float(img06arr))\n",
    "mse7 = compare_mse(img_as_float(img00arr), img_as_float(img07arr))\n",
    "mse8 = compare_mse(img_as_float(img00arr), img_as_float(img08arr))\n",
    "mse9 = compare_mse(img_as_float(img00arr), img_as_float(img09arr))\n",
    "mse10 = compare_mse(img_as_float(img00arr), img_as_float(img10arr))\n",
    "mse11 = compare_mse(img_as_float(img00arr), img_as_float(img11arr))\n",
    "\n",
    "print(\"SSIM ------------------------\")\n",
    "print(\"Q-Learning: \", ssim2)\n",
    "print(\"DQN-1000nn: \", ssim1)\n",
    "#print(\"DQN-1500nn: \", ssim3)\n",
    "print(\"importance sampling: \", ssim4)\n",
    "print(\"DQN-1000nn noise reduction: \", ssim5)\n",
    "print(\"DQN-1000nn 2: \", ssim6)\n",
    "print(\"Q-Learning 2: \", ssim7)\n",
    "print(\"Q-Learning 2, noise reduction depth 6: \", ssim8)\n",
    "print(\"Q-Learning 2, depth 6: \", ssim9)\n",
    "print(\"DQN noise reduction: \", ssim10)\n",
    "print(\"DQN noise reduction: \", ssim11)\n",
    "\n",
    "print(\"MSE --------------\")\n",
    "print(\"Q-Learning: \", mse2)\n",
    "print(\"DQN-1000nn: \", mse1)\n",
    "#print(\"DQN-1500nn: \", mse3)\n",
    "print(\"importance sampling: \", mse4)\n",
    "print(\"DQN-1000nn noise reduction: \", mse5)\n",
    "print(\"DQN-1000nn 2: \", mse6)\n",
    "print(\"Q-Learning 2: \", mse7)\n",
    "print(\"Q-Learning 2, depth 6: \", mse9)\n",
    "print(\"DQN noise reduction: \", mse10)\n",
    "print(\"DQN noise reduction: \", mse11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T09:41:14.549831Z",
     "start_time": "2019-09-25T09:41:14.480005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM ---------------\n",
      "0.03873196744617331\n",
      "0.045803959191237587\n",
      "0.03328748879975807\n",
      "0.030413803539436474\n",
      "0.0373165021483807\n",
      "\n",
      "MSE ---------------\n",
      "0.06608379532368502\n",
      "0.05148091278995258\n",
      "0.0715185928946742\n",
      "0.06829936431271855\n",
      "0.05260351931698946\n"
     ]
    }
   ],
   "source": [
    "# IQA BETWEEN RESIZED IMAGES [30 X 256]\n",
    "from skimage.measure import compare_ssim, compare_mse\n",
    "from skimage import img_as_float\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "# Load images\n",
    "ref = Image.open('scenedqn3-5120spp-explicit-256.png').convert(\"RGB\")\n",
    "old_dqn = Image.open('py-smallpt-3-10000L2000-72actions-lineareps-lr00001-1000nnx4-KERNEL16-targetnet-32spp-256.png').convert(\"RGB\")\n",
    "q = Image.open('scenedqn3-32spp-qlearning-256-tr128.png').convert(\"RGB\")\n",
    "dqn2 = Image.open('py-smallpt3-10000L2000-72actions-lineareps-lr00001-1000nnx4-KERNEL16-targetnet-32spp-256-noisereduction-31.png').convert(\"RGB\")\n",
    "dqn3 = Image.open('py-smallpt3-10000L2000-72actions-lineareps-lr00001-1000nnx4-KERNEL16-targetnet-2.png').convert(\"RGB\")\n",
    "dqn4 = Image.open('py-smallpt3-TO-CHECK-IF-ITS-512kb-DEPTH-AFTER - Copy.png').convert(\"RGB\")\n",
    "\n",
    "# Load arrays from images\n",
    "refarray= np.array(ref) \n",
    "old_dqn_array =  np.array(old_dqn) \n",
    "q_array = np.array(q)\n",
    "dqn2_array = np.array(dqn2)\n",
    "dqn3_array = np.array(dqn3)\n",
    "dqn4_array = np.array(dqn4)\n",
    "\n",
    "\n",
    "#Reduce arrays\n",
    "ref_reduced_array = refarray[:70][:]\n",
    "old_dqn_reduced_array = old_dqn_array[:70][:]\n",
    "q_array = q_array[:70][:]\n",
    "dqn2_array = dqn2_array[:70][:]\n",
    "dqn3_array = dqn3_array[:70][:]\n",
    "dqn4_array = dqn4_array[:70][:]\n",
    "\n",
    "\n",
    "\n",
    "# Compare ssim\n",
    "ssim1 = compare_ssim(ref_reduced_array, old_dqn_reduced_array, multichannel=True)\n",
    "ssim2 = compare_ssim(ref_reduced_array, q_array, multichannel=True)\n",
    "ssim3 = compare_ssim(ref_reduced_array, dqn2_array, multichannel=True)\n",
    "ssim4 = compare_ssim(ref_reduced_array, dqn3_array, multichannel=True)\n",
    "ssim5= compare_ssim(ref_reduced_array, dqn4_array, multichannel=True)\n",
    "\n",
    "# Compare mse\n",
    "mse1= compare_mse(img_as_float(ref_reduced_array), img_as_float(old_dqn_reduced_array))\n",
    "mse2= compare_mse(img_as_float(ref_reduced_array), img_as_float(q_array))\n",
    "mse3= compare_mse(img_as_float(ref_reduced_array), img_as_float(dqn2_array))\n",
    "mse4= compare_mse(img_as_float(ref_reduced_array), img_as_float(dqn3_array))\n",
    "mse4= compare_mse(img_as_float(ref_reduced_array), img_as_float(dqn4_array))\n",
    "\n",
    "# print ssim\n",
    "print(\"SSIM ---------------\")\n",
    "print(ssim1)\n",
    "print(ssim2)\n",
    "print(ssim3)\n",
    "print(ssim4)\n",
    "print(ssim5)\n",
    "\n",
    "#Print MSE\n",
    "print(\"\\nMSE ---------------\")\n",
    "print(mse1)\n",
    "print(mse2)\n",
    "print(mse3)\n",
    "print(mse4)\n",
    "print(mse5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
